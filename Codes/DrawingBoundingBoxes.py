from ctypes import sizeof
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
import torch
import torchvision
from torchvision.io import read_image
from torchvision.utils import draw_bounding_boxes
import os
from os import listdir
import tensorflow as tf
import pathlib as Path
import imghdr
from collections import defaultdict
import json
import sys
import math


#Here we're importing all project functions
import funciones
import newSize_augment_anchors


#Avoid the use of all MEM
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)


#Here we define the configuration class we will use in order to manage data correctly
class configuration:

    def __init__(self):
                
            # Print the process or not
            self.verbose = True

            # Name of base network
            self.network = 'vgg'

            # Setting for data augmentation
            self.use_horizontal_flips = False
            self.use_vertical_flips = False
            self.rot_90 = False

            # Anchor box scales
            # Note that if im_size is smaller, anchor_box_scales should be scaled
            # Original anchor_box_scales in the paper is [128, 256, 512]
            
            self.anchor_box_scales = [16, 32, 64] #this is must to achieve multiscale detection

            # Anchor box ratios
            self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]

            # Size to resize the smallest side of the image
            # Original setting in paper is 600. Set to 300 in here to save training time
            self.im_size = 300

            # image channel-wise mean to subtract
            self.img_channel_mean = [103.939, 116.779, 123.68]
            self.img_scaling_factor = 1.0

            # number of ROIs at once
            self.num_rois = 4

            # stride at the RPN (this depends on the network configuration)
            self.rpn_stride = 16

            self.balanced_classes = True

            # scaling the stdev
            self.std_scaling = 4.0
            self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

            # overlaps for RPN
            self.rpn_min_overlap = 0.3
            self.rpn_max_overlap = 0.7

            # overlaps for classifier ROIs
            self.classifier_min_overlap = 0.1
            self.classifier_max_overlap = 0.5

            # placeholder for the class mapping, automatically generated by the parser
            self.class_mapping = None

            self.model_path = None

#Paths

#base_path = ''
#train_path =  ''
output_weight_path = '/Users/pablosreyero/Documents/Universidad/TFG/tfg-psr/data/Model/model_frcnn_vgg.hdf5'
record_path = '/Users/pablosreyero/Documents/Universidad/TFG/tfg-psr/data/Model/record.csv'
base_weight_path =  '/Users/pablosreyero/Documents/Universidad/TFG/tfg-psr/data/Model/vgg16_weights_tf_dim_ordering_tf_kernels.h5'
config_output_filename = '/Users/pablosreyero/Documents/Universidad/TFG/tfg-psr/data/Model/model_vgg_config.pickle'
num_rois = 4

#Data augmentation profile
horizontal_flips = True
vertical_flips = True 
rot_90 = True

#Now we create the associated objects of the upper class
C = configuration()

C.use_horizontal_flips = horizontal_flips
C.use_vertical_flips = vertical_flips
C.rot_90 = rot_90
C.num_rois = num_rois


C.record_path = record_path
C.model_path = output_weight_path
C.base_net_weights = base_weight_path


#Calling the main to invoke other functions
funciones.main(C,output_weight_path,record_path,base_weight_path,config_output_filename)